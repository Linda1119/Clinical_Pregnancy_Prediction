{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "L48cVms5Rvin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "df_train = pd.read_csv('./train.csv')\n",
        "df_test = pd.read_csv('./test.csv')\n",
        "df_sample_submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "31tbRHcdeqMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ID Ï†úÍ±∞\n",
        "df_train.drop(columns=['ID'], inplace=True)\n",
        "df_test_ids = df_test['ID']\n",
        "df_test.drop(columns=['ID'], inplace=True)"
      ],
      "metadata": {
        "id": "7j-TRKBxesKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌÉÄÍ≤ü Î≥ÄÏàò Î∂ÑÎ¶¨\n",
        "X = df_train.drop(columns=['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä'])\n",
        "y = df_train['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä']"
      ],
      "metadata": {
        "id": "vGVs0ogaeuQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Í≤∞Ï∏°Ïπò ÌôïÏù∏ Î∞è Ï≤òÎ¶¨\n",
        "print(\"üìä Í≤∞Ï∏°Ïπò Í∞úÏàò:\")\n",
        "print(X.isnull().sum())"
      ],
      "metadata": {
        "id": "Pl8tcMsPevTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e53270b-3b81-4255-f3d7-ad95588adbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Í≤∞Ï∏°Ïπò Í∞úÏàò:\n",
            "ÏãúÏà† ÏãúÍ∏∞ ÏΩîÎìú                      0\n",
            "ÏãúÏà† ÎãπÏãú ÎÇòÏù¥                      0\n",
            "ÏûÑÏã† ÏãúÎèÑ ÎòêÎäî ÎßàÏßÄÎßâ ÏûÑÏã† Í≤ΩÍ≥º Ïó∞Ïàò    246981\n",
            "ÏãúÏà† Ïú†Ìòï                         0\n",
            "ÌäπÏ†ï ÏãúÏà† Ïú†Ìòï                      2\n",
            "                          ...  \n",
            "ÎÇúÏûê Ï±ÑÏ∑® Í≤ΩÍ≥ºÏùº                 57488\n",
            "ÎÇúÏûê Ìï¥Îèô Í≤ΩÍ≥ºÏùº                254915\n",
            "ÎÇúÏûê ÌòºÌï© Í≤ΩÍ≥ºÏùº                 53735\n",
            "Î∞∞ÏïÑ Ïù¥Ïãù Í≤ΩÍ≥ºÏùº                 43566\n",
            "Î∞∞ÏïÑ Ìï¥Îèô Í≤ΩÍ≥ºÏùº                215982\n",
            "Length: 67, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïà´ÏûêÌòï Î≥ÄÏàò Í≤∞Ï∏°Ïπò ÌèâÍ∑† ÎåÄÏ≤¥\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X[numeric_features] = imputer.fit_transform(X[numeric_features])\n",
        "df_test[numeric_features] = imputer.transform(df_test[numeric_features])"
      ],
      "metadata": {
        "id": "e8HGyrWXXABN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î≤îÏ£ºÌòï Î≥ÄÏàò Ïù∏ÏΩîÎî© (Ordinal Encoding)\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X[categorical_features] = encoder.fit_transform(X[categorical_features])\n",
        "df_test[categorical_features] = encoder.transform(df_test[categorical_features])"
      ],
      "metadata": {
        "id": "cgz6l8FjezWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Feature Scaling (StandardScaler Ï†ÅÏö©) ‚Üí Î®ºÏ†Ä Ï†ÅÏö©\n",
        "scaler = StandardScaler()\n",
        "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
        "df_test[numeric_features] = scaler.transform(df_test[numeric_features])\n"
      ],
      "metadata": {
        "id": "4eR2btZ8mZ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Feature Selection (LightGBM Í∏∞Î∞ò, ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï)\n",
        "lgbm = LGBMClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "lgbm.fit(X, y)\n",
        "feature_importance = pd.Series(lgbm.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "selected_features = feature_importance[feature_importance > 0.0005].index.tolist()\n",
        "X = X[selected_features]\n",
        "df_test = df_test[selected_features]"
      ],
      "metadata": {
        "id": "O12i-WjWe7Ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108f6666-d2b7-4783-ee61-896627928f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 66228, number of negative: 190123\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093993 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 771\n",
            "[LightGBM] [Info] Number of data points in the train set: 256351, number of used features: 60\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054568\n",
            "[LightGBM] [Info] Start training from score -1.054568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Feature Selection Ïù¥ÌõÑ NaN Ï≤¥ÌÅ¨ Î∞è Ïû¨Ï≤òÎ¶¨\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "df_test = pd.DataFrame(imputer.transform(df_test), columns=df_test.columns)"
      ],
      "metadata": {
        "id": "aug-rMGuYuuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌõàÎ†® / Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TCbpV4tgg8DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Optuna ÏµúÏ†ÅÌôî Ìï®Ïàò Ï†ïÏùò\n",
        "def objective(trial):\n",
        "    # Í∞úÎ≥Ñ Î™®Îç∏Ïùò ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù\n",
        "    lgbm_params = {\n",
        "        'n_estimators': trial.suggest_int('lgbm_n_estimators', 300, 500),\n",
        "        'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
        "        'num_leaves': trial.suggest_int('lgbm_num_leaves', 30, 100),\n",
        "        'max_depth': trial.suggest_int('lgbm_max_depth', 4, 12),\n",
        "        'subsample': trial.suggest_float('lgbm_subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('lgbm_colsample_bytree', 0.5, 1.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 300, 500),\n",
        "        'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 4, 12),\n",
        "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    catboost_params = {\n",
        "        'iterations': trial.suggest_int('catboost_iterations', 300, 500),\n",
        "        'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
        "        'depth': trial.suggest_int('catboost_depth', 4, 12),\n",
        "        'l2_leaf_reg': trial.suggest_float('catboost_l2_leaf_reg', 2, 10),\n",
        "        'random_state': 42,\n",
        "        'verbose': 0\n",
        "    }\n",
        "\n",
        "    # üîπ Í∞úÎ≥Ñ Î™®Îç∏ Ï†ïÏùò (Optuna ÌäúÎãù Ï†ÅÏö©)\n",
        "    lgbm = LGBMClassifier(**lgbm_params)\n",
        "    xgb = XGBClassifier(**xgb_params)\n",
        "    catboost = CatBoostClassifier(**catboost_params)\n",
        "\n",
        "    # üîπ Meta Model ÏÑ†ÌÉù (Logistic Regression vs Random Forest)\n",
        "    meta_model_choice = trial.suggest_categorical('meta_model', ['logistic', 'random_forest'])\n",
        "\n",
        "    if meta_model_choice == 'logistic':\n",
        "        meta_model = LogisticRegression()\n",
        "    else:\n",
        "        meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # üîπ Stacking Î™®Îç∏ ÏÑ§Ï†ï\n",
        "    stacked_model = StackingClassifier(\n",
        "        estimators=[\n",
        "            ('lgbm', lgbm),\n",
        "            ('xgb', xgb),\n",
        "            ('catboost', catboost)\n",
        "        ],\n",
        "        final_estimator=meta_model,\n",
        "        stack_method='predict_proba',\n",
        "        passthrough=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # üîπ Stacking ÌïôÏäµ\n",
        "    stacked_model.fit(X_train, y_train)\n",
        "\n",
        "    # üîπ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
        "    y_val_pred = stacked_model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(y_val, y_val_pred)"
      ],
      "metadata": {
        "id": "BoHMYaHSe9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Optuna Ïã§Ìñâ\n",
        "study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi_dHCnqE1Yu",
        "outputId": "c63e76ea-4853-400a-e146-49995c361085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-04 11:18:06,610] A new study created in memory with name: no-name-8daaa62a-b808-435e-930f-815253868960\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "[I 2025-02-04 11:25:15,286] Trial 0 finished with value: 0.7139404937098265 and parameters: {'lgbm_n_estimators': 388, 'lgbm_learning_rate': 0.0042642770385571665, 'lgbm_num_leaves': 49, 'lgbm_max_depth': 6, 'lgbm_subsample': 0.5862004045294973, 'lgbm_colsample_bytree': 0.5609140602881211, 'xgb_n_estimators': 465, 'xgb_learning_rate': 0.0037380970261726653, 'xgb_max_depth': 9, 'xgb_subsample': 0.6714500597558724, 'xgb_colsample_bytree': 0.9465809988655078, 'catboost_iterations': 358, 'catboost_learning_rate': 0.0049790268126221815, 'catboost_depth': 4, 'catboost_l2_leaf_reg': 4.578384298942155, 'meta_model': 'random_forest'}. Best is trial 0 with value: 0.7139404937098265.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 11:37:52,464] Trial 1 finished with value: 0.7347737798583946 and parameters: {'lgbm_n_estimators': 479, 'lgbm_learning_rate': 0.007197089173003058, 'lgbm_num_leaves': 32, 'lgbm_max_depth': 4, 'lgbm_subsample': 0.8115022717167799, 'lgbm_colsample_bytree': 0.975796708744527, 'xgb_n_estimators': 421, 'xgb_learning_rate': 0.004954349582550549, 'xgb_max_depth': 11, 'xgb_subsample': 0.6509250923402046, 'xgb_colsample_bytree': 0.5980882785007611, 'catboost_iterations': 381, 'catboost_learning_rate': 0.00467051790664945, 'catboost_depth': 11, 'catboost_l2_leaf_reg': 6.01934185028557, 'meta_model': 'logistic'}. Best is trial 1 with value: 0.7347737798583946.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "[I 2025-02-04 11:44:57,128] Trial 2 finished with value: 0.7150407056228482 and parameters: {'lgbm_n_estimators': 358, 'lgbm_learning_rate': 0.0037514594661509125, 'lgbm_num_leaves': 74, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.7083222749306259, 'lgbm_colsample_bytree': 0.9249876893922138, 'xgb_n_estimators': 417, 'xgb_learning_rate': 0.01466853825985716, 'xgb_max_depth': 4, 'xgb_subsample': 0.8089139057195993, 'xgb_colsample_bytree': 0.9338557060425676, 'catboost_iterations': 474, 'catboost_learning_rate': 0.0044583697137734225, 'catboost_depth': 6, 'catboost_l2_leaf_reg': 7.150362668784714, 'meta_model': 'random_forest'}. Best is trial 1 with value: 0.7347737798583946.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 11:50:24,041] Trial 3 finished with value: 0.7347795758452109 and parameters: {'lgbm_n_estimators': 418, 'lgbm_learning_rate': 0.007550528202412179, 'lgbm_num_leaves': 81, 'lgbm_max_depth': 8, 'lgbm_subsample': 0.6299889739947333, 'lgbm_colsample_bytree': 0.7366015809113847, 'xgb_n_estimators': 306, 'xgb_learning_rate': 0.009755372157346204, 'xgb_max_depth': 5, 'xgb_subsample': 0.9316490140669367, 'xgb_colsample_bytree': 0.5977959084080785, 'catboost_iterations': 403, 'catboost_learning_rate': 0.003939223376785364, 'catboost_depth': 5, 'catboost_l2_leaf_reg': 6.057145626030238, 'meta_model': 'logistic'}. Best is trial 3 with value: 0.7347795758452109.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "[I 2025-02-04 11:59:55,101] Trial 4 finished with value: 0.7150428296862456 and parameters: {'lgbm_n_estimators': 494, 'lgbm_learning_rate': 0.0045565592717142335, 'lgbm_num_leaves': 30, 'lgbm_max_depth': 9, 'lgbm_subsample': 0.8587179503707922, 'lgbm_colsample_bytree': 0.614251543881327, 'xgb_n_estimators': 481, 'xgb_learning_rate': 0.005042193388269385, 'xgb_max_depth': 12, 'xgb_subsample': 0.9495163322351318, 'xgb_colsample_bytree': 0.8937876170358298, 'catboost_iterations': 421, 'catboost_learning_rate': 0.005046254303607474, 'catboost_depth': 6, 'catboost_l2_leaf_reg': 2.825721292855576, 'meta_model': 'random_forest'}. Best is trial 3 with value: 0.7347795758452109.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "[I 2025-02-04 12:08:14,849] Trial 5 finished with value: 0.7136942221900534 and parameters: {'lgbm_n_estimators': 423, 'lgbm_learning_rate': 0.006070408486679305, 'lgbm_num_leaves': 62, 'lgbm_max_depth': 5, 'lgbm_subsample': 0.9976145790164843, 'lgbm_colsample_bytree': 0.5247379264867398, 'xgb_n_estimators': 309, 'xgb_learning_rate': 0.007199314967067093, 'xgb_max_depth': 4, 'xgb_subsample': 0.8730214035030224, 'xgb_colsample_bytree': 0.6586396229762179, 'catboost_iterations': 494, 'catboost_learning_rate': 0.006508112771206939, 'catboost_depth': 9, 'catboost_l2_leaf_reg': 8.407330783011894, 'meta_model': 'random_forest'}. Best is trial 3 with value: 0.7347795758452109.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 12:14:46,181] Trial 6 finished with value: 0.7339892405154178 and parameters: {'lgbm_n_estimators': 462, 'lgbm_learning_rate': 0.007321221318242676, 'lgbm_num_leaves': 65, 'lgbm_max_depth': 6, 'lgbm_subsample': 0.9088951586237259, 'lgbm_colsample_bytree': 0.8652691199142615, 'xgb_n_estimators': 381, 'xgb_learning_rate': 0.004935416575811712, 'xgb_max_depth': 6, 'xgb_subsample': 0.7460822262022514, 'xgb_colsample_bytree': 0.8549732583728524, 'catboost_iterations': 398, 'catboost_learning_rate': 0.005513609614148534, 'catboost_depth': 8, 'catboost_l2_leaf_reg': 4.84545622652488, 'meta_model': 'logistic'}. Best is trial 3 with value: 0.7347795758452109.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "[I 2025-02-04 12:20:25,578] Trial 7 finished with value: 0.7126608378851902 and parameters: {'lgbm_n_estimators': 312, 'lgbm_learning_rate': 0.005976082297491503, 'lgbm_num_leaves': 92, 'lgbm_max_depth': 9, 'lgbm_subsample': 0.5006268347419837, 'lgbm_colsample_bytree': 0.9895423154320799, 'xgb_n_estimators': 435, 'xgb_learning_rate': 0.004034058900061118, 'xgb_max_depth': 4, 'xgb_subsample': 0.80399603591613, 'xgb_colsample_bytree': 0.6389184507292616, 'catboost_iterations': 335, 'catboost_learning_rate': 0.008405550898216154, 'catboost_depth': 4, 'catboost_l2_leaf_reg': 2.2877544529135774, 'meta_model': 'random_forest'}. Best is trial 3 with value: 0.7347795758452109.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 12:33:12,859] Trial 8 finished with value: 0.7350233508165621 and parameters: {'lgbm_n_estimators': 477, 'lgbm_learning_rate': 0.0049358171531007885, 'lgbm_num_leaves': 67, 'lgbm_max_depth': 7, 'lgbm_subsample': 0.8640642558573046, 'lgbm_colsample_bytree': 0.5095645887263407, 'xgb_n_estimators': 428, 'xgb_learning_rate': 0.009975149706756338, 'xgb_max_depth': 8, 'xgb_subsample': 0.8336131926376786, 'xgb_colsample_bytree': 0.6206604304624349, 'catboost_iterations': 374, 'catboost_learning_rate': 0.007288539266249075, 'catboost_depth': 11, 'catboost_l2_leaf_reg': 7.578342957649466, 'meta_model': 'logistic'}. Best is trial 8 with value: 0.7350233508165621.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "[I 2025-02-04 12:40:48,035] Trial 9 finished with value: 0.7151021906173838 and parameters: {'lgbm_n_estimators': 499, 'lgbm_learning_rate': 0.004364816074486849, 'lgbm_num_leaves': 46, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.5557617665749475, 'lgbm_colsample_bytree': 0.8344283324785495, 'xgb_n_estimators': 497, 'xgb_learning_rate': 0.012769521194315807, 'xgb_max_depth': 7, 'xgb_subsample': 0.6526966765239708, 'xgb_colsample_bytree': 0.9286440855506515, 'catboost_iterations': 492, 'catboost_learning_rate': 0.01482550288208935, 'catboost_depth': 4, 'catboost_l2_leaf_reg': 4.685558009042916, 'meta_model': 'random_forest'}. Best is trial 8 with value: 0.7350233508165621.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 12:53:06,721] Trial 10 finished with value: 0.735135829310545 and parameters: {'lgbm_n_estimators': 444, 'lgbm_learning_rate': 0.013638522785237396, 'lgbm_num_leaves': 99, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.7224404375457828, 'lgbm_colsample_bytree': 0.6508118385419621, 'xgb_n_estimators': 359, 'xgb_learning_rate': 0.008658583837617752, 'xgb_max_depth': 8, 'xgb_subsample': 0.5301859315159263, 'xgb_colsample_bytree': 0.5158754307529483, 'catboost_iterations': 300, 'catboost_learning_rate': 0.010034686306646319, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.974101082343989, 'meta_model': 'logistic'}. Best is trial 10 with value: 0.735135829310545.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 13:05:47,853] Trial 11 finished with value: 0.7351216668906569 and parameters: {'lgbm_n_estimators': 455, 'lgbm_learning_rate': 0.014803572163205308, 'lgbm_num_leaves': 99, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.7152993565405825, 'lgbm_colsample_bytree': 0.6681098613850607, 'xgb_n_estimators': 367, 'xgb_learning_rate': 0.008635146007228672, 'xgb_max_depth': 9, 'xgb_subsample': 0.5496164617759027, 'xgb_colsample_bytree': 0.5424150108144233, 'catboost_iterations': 304, 'catboost_learning_rate': 0.009725065616098658, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.733993282584347, 'meta_model': 'logistic'}. Best is trial 10 with value: 0.735135829310545.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 13:18:42,768] Trial 12 finished with value: 0.7353142686110744 and parameters: {'lgbm_n_estimators': 440, 'lgbm_learning_rate': 0.01437883788171749, 'lgbm_num_leaves': 100, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.7029043094354271, 'lgbm_colsample_bytree': 0.6825966945484504, 'xgb_n_estimators': 363, 'xgb_learning_rate': 0.007737078625607314, 'xgb_max_depth': 10, 'xgb_subsample': 0.5024239843915708, 'xgb_colsample_bytree': 0.5071446741293296, 'catboost_iterations': 301, 'catboost_learning_rate': 0.011462771291351431, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.799575742203306, 'meta_model': 'logistic'}. Best is trial 12 with value: 0.7353142686110744.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 13:31:17,082] Trial 13 finished with value: 0.7353481018352888 and parameters: {'lgbm_n_estimators': 436, 'lgbm_learning_rate': 0.014768177339829039, 'lgbm_num_leaves': 87, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.6628572716745862, 'lgbm_colsample_bytree': 0.7129596637133632, 'xgb_n_estimators': 347, 'xgb_learning_rate': 0.006945354657061471, 'xgb_max_depth': 10, 'xgb_subsample': 0.5033839027206597, 'xgb_colsample_bytree': 0.5110990994971739, 'catboost_iterations': 300, 'catboost_learning_rate': 0.011409195641314061, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.955027922167531, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 13:38:08,770] Trial 14 finished with value: 0.7350885766392531 and parameters: {'lgbm_n_estimators': 390, 'lgbm_learning_rate': 0.010658988333845796, 'lgbm_num_leaves': 87, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.6473435441429267, 'lgbm_colsample_bytree': 0.7509405540324385, 'xgb_n_estimators': 343, 'xgb_learning_rate': 0.0066045039621391065, 'xgb_max_depth': 10, 'xgb_subsample': 0.503964579807254, 'xgb_colsample_bytree': 0.7422499223786594, 'catboost_iterations': 338, 'catboost_learning_rate': 0.014464458921063848, 'catboost_depth': 9, 'catboost_l2_leaf_reg': 8.7632875033312, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 13:48:20,944] Trial 15 finished with value: 0.7349167462017063 and parameters: {'lgbm_n_estimators': 423, 'lgbm_learning_rate': 0.01049862934627853, 'lgbm_num_leaves': 87, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.7729299176999179, 'lgbm_colsample_bytree': 0.7435012173857364, 'xgb_n_estimators': 336, 'xgb_learning_rate': 0.006558953221919643, 'xgb_max_depth': 11, 'xgb_subsample': 0.5883302395047956, 'xgb_colsample_bytree': 0.7273079934728659, 'catboost_iterations': 327, 'catboost_learning_rate': 0.011676916188948767, 'catboost_depth': 10, 'catboost_l2_leaf_reg': 8.944904778355244, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 14:02:20,281] Trial 16 finished with value: 0.7347557627677431 and parameters: {'lgbm_n_estimators': 362, 'lgbm_learning_rate': 0.010999530803427823, 'lgbm_num_leaves': 80, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.6643837660588024, 'lgbm_colsample_bytree': 0.7993363470426539, 'xgb_n_estimators': 395, 'xgb_learning_rate': 0.0030517733543072253, 'xgb_max_depth': 10, 'xgb_subsample': 0.5943402648408997, 'xgb_colsample_bytree': 0.5034382113077394, 'catboost_iterations': 451, 'catboost_learning_rate': 0.0030158195288951645, 'catboost_depth': 11, 'catboost_l2_leaf_reg': 7.531903471149098, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 14:09:27,324] Trial 17 finished with value: 0.7345218681364266 and parameters: {'lgbm_n_estimators': 440, 'lgbm_learning_rate': 0.012316186975904895, 'lgbm_num_leaves': 92, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.7733017785801743, 'lgbm_colsample_bytree': 0.7028442659944424, 'xgb_n_estimators': 330, 'xgb_learning_rate': 0.005849431598428424, 'xgb_max_depth': 12, 'xgb_subsample': 0.7000029212469572, 'xgb_colsample_bytree': 0.8338429028007189, 'catboost_iterations': 320, 'catboost_learning_rate': 0.011390790887471974, 'catboost_depth': 8, 'catboost_l2_leaf_reg': 9.256576228745828, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 14:24:14,668] Trial 18 finished with value: 0.735273177421288 and parameters: {'lgbm_n_estimators': 404, 'lgbm_learning_rate': 0.009109552860028607, 'lgbm_num_leaves': 98, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.5964953755719862, 'lgbm_colsample_bytree': 0.6100585103387828, 'xgb_n_estimators': 365, 'xgb_learning_rate': 0.007804678572875007, 'xgb_max_depth': 10, 'xgb_subsample': 0.5930114482949862, 'xgb_colsample_bytree': 0.5527277776513189, 'catboost_iterations': 357, 'catboost_learning_rate': 0.012043851646633809, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 8.50259701077877, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 14:33:41,220] Trial 19 finished with value: 0.7350054974994871 and parameters: {'lgbm_n_estimators': 342, 'lgbm_learning_rate': 0.009199543121912136, 'lgbm_num_leaves': 76, 'lgbm_max_depth': 8, 'lgbm_subsample': 0.6734748931479957, 'lgbm_colsample_bytree': 0.7869318775314013, 'xgb_n_estimators': 395, 'xgb_learning_rate': 0.011483085852758715, 'xgb_max_depth': 9, 'xgb_subsample': 0.5057915478876683, 'xgb_colsample_bytree': 0.6957562447481098, 'catboost_iterations': 314, 'catboost_learning_rate': 0.0086852443972296, 'catboost_depth': 10, 'catboost_l2_leaf_reg': 6.850665616013352, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 14:44:54,932] Trial 20 finished with value: 0.7347622098543879 and parameters: {'lgbm_n_estimators': 439, 'lgbm_learning_rate': 0.012566781003107826, 'lgbm_num_leaves': 89, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.5010714412181652, 'lgbm_colsample_bytree': 0.685529869080296, 'xgb_n_estimators': 327, 'xgb_learning_rate': 0.0057806384000646865, 'xgb_max_depth': 11, 'xgb_subsample': 0.5626583527834411, 'xgb_colsample_bytree': 0.8087995174928607, 'catboost_iterations': 351, 'catboost_learning_rate': 0.007395653500091931, 'catboost_depth': 10, 'catboost_l2_leaf_reg': 8.133971703847205, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 15:00:48,294] Trial 21 finished with value: 0.7350959284750461 and parameters: {'lgbm_n_estimators': 408, 'lgbm_learning_rate': 0.008726541179434803, 'lgbm_num_leaves': 100, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.5918298356236174, 'lgbm_colsample_bytree': 0.609213742322434, 'xgb_n_estimators': 363, 'xgb_learning_rate': 0.007709093192912534, 'xgb_max_depth': 10, 'xgb_subsample': 0.6065754234459979, 'xgb_colsample_bytree': 0.5507008874839779, 'catboost_iterations': 352, 'catboost_learning_rate': 0.012060002444517775, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.936610838966534, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 15:12:24,448] Trial 22 finished with value: 0.7352426815830042 and parameters: {'lgbm_n_estimators': 391, 'lgbm_learning_rate': 0.014722978574100768, 'lgbm_num_leaves': 95, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.6033744980417163, 'lgbm_colsample_bytree': 0.6053844391530414, 'xgb_n_estimators': 354, 'xgb_learning_rate': 0.007940865282859075, 'xgb_max_depth': 10, 'xgb_subsample': 0.5497418356540194, 'xgb_colsample_bytree': 0.5640318384902676, 'catboost_iterations': 300, 'catboost_learning_rate': 0.013163716640379257, 'catboost_depth': 11, 'catboost_l2_leaf_reg': 9.20607467807976, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 15:28:49,363] Trial 23 finished with value: 0.7353085305441814 and parameters: {'lgbm_n_estimators': 375, 'lgbm_learning_rate': 0.00942954243004362, 'lgbm_num_leaves': 83, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.5534084471577952, 'lgbm_colsample_bytree': 0.5691034424950633, 'xgb_n_estimators': 373, 'xgb_learning_rate': 0.00983403113892696, 'xgb_max_depth': 9, 'xgb_subsample': 0.6185215656672112, 'xgb_colsample_bytree': 0.5025721640518341, 'catboost_iterations': 371, 'catboost_learning_rate': 0.010467840237254732, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 8.426478767942449, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 15:47:07,491] Trial 24 finished with value: 0.7351381481047193 and parameters: {'lgbm_n_estimators': 368, 'lgbm_learning_rate': 0.012185954336665684, 'lgbm_num_leaves': 82, 'lgbm_max_depth': 9, 'lgbm_subsample': 0.5432361405839188, 'lgbm_colsample_bytree': 0.5670772198511576, 'xgb_n_estimators': 381, 'xgb_learning_rate': 0.010507880374795251, 'xgb_max_depth': 7, 'xgb_subsample': 0.6948305779614896, 'xgb_colsample_bytree': 0.5030128250375102, 'catboost_iterations': 431, 'catboost_learning_rate': 0.010073105963606986, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.46731734887184, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 16:00:28,675] Trial 25 finished with value: 0.7350482064526509 and parameters: {'lgbm_n_estimators': 334, 'lgbm_learning_rate': 0.010316786628542723, 'lgbm_num_leaves': 74, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.6861077692573762, 'lgbm_colsample_bytree': 0.6494822292386914, 'xgb_n_estimators': 380, 'xgb_learning_rate': 0.008978211481279811, 'xgb_max_depth': 9, 'xgb_subsample': 0.6258325530649669, 'xgb_colsample_bytree': 0.6805034194777686, 'catboost_iterations': 377, 'catboost_learning_rate': 0.00895293446442402, 'catboost_depth': 11, 'catboost_l2_leaf_reg': 7.946273466120514, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 16:07:25,550] Trial 26 finished with value: 0.7348761043906358 and parameters: {'lgbm_n_estimators': 378, 'lgbm_learning_rate': 0.003049414031488612, 'lgbm_num_leaves': 85, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.5519109345225339, 'lgbm_colsample_bytree': 0.7177581221948965, 'xgb_n_estimators': 320, 'xgb_learning_rate': 0.011544305084667673, 'xgb_max_depth': 7, 'xgb_subsample': 0.7288286420280976, 'xgb_colsample_bytree': 0.5845288432292717, 'catboost_iterations': 323, 'catboost_learning_rate': 0.010933449510610848, 'catboost_depth': 9, 'catboost_l2_leaf_reg': 9.294889189289956, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 16:19:16,394] Trial 27 finished with value: 0.7352521864421564 and parameters: {'lgbm_n_estimators': 461, 'lgbm_learning_rate': 0.012832153664756766, 'lgbm_num_leaves': 57, 'lgbm_max_depth': 11, 'lgbm_subsample': 0.6295546328522243, 'lgbm_colsample_bytree': 0.5494064037745495, 'xgb_n_estimators': 347, 'xgb_learning_rate': 0.005983162824296821, 'xgb_max_depth': 11, 'xgb_subsample': 0.5115593570514185, 'xgb_colsample_bytree': 0.5271332581870943, 'catboost_iterations': 341, 'catboost_learning_rate': 0.013123418898970758, 'catboost_depth': 10, 'catboost_l2_leaf_reg': 6.481130642581971, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[I 2025-02-04 16:36:46,331] Trial 28 finished with value: 0.735170089943849 and parameters: {'lgbm_n_estimators': 430, 'lgbm_learning_rate': 0.008239678318966916, 'lgbm_num_leaves': 70, 'lgbm_max_depth': 10, 'lgbm_subsample': 0.7422598231790217, 'lgbm_colsample_bytree': 0.7930888032494519, 'xgb_n_estimators': 443, 'xgb_learning_rate': 0.013838357807546917, 'xgb_max_depth': 8, 'xgb_subsample': 0.5692030997585009, 'xgb_colsample_bytree': 0.992531813452749, 'catboost_iterations': 392, 'catboost_learning_rate': 0.007947010021828183, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 8.80499529236346, 'meta_model': 'logistic'}. Best is trial 13 with value: 0.7353481018352888.\n",
            "<ipython-input-14-9713eceb3535>:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('lgbm_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.003, 0.015),\n",
            "<ipython-input-14-9713eceb3535>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('catboost_learning_rate', 0.003, 0.015),\n",
            "[I 2025-02-04 16:46:06,043] Trial 29 finished with value: 0.7146744769486395 and parameters: {'lgbm_n_estimators': 412, 'lgbm_learning_rate': 0.01151572020781665, 'lgbm_num_leaves': 92, 'lgbm_max_depth': 8, 'lgbm_subsample': 0.804109847333253, 'lgbm_colsample_bytree': 0.56573035842388, 'xgb_n_estimators': 407, 'xgb_learning_rate': 0.011301429637787115, 'xgb_max_depth': 9, 'xgb_subsample': 0.6429010603424015, 'xgb_colsample_bytree': 0.571140887406787, 'catboost_iterations': 364, 'catboost_learning_rate': 0.0066173098772140445, 'catboost_depth': 8, 'catboost_l2_leaf_reg': 3.696603702231908, 'meta_model': 'random_forest'}. Best is trial 13 with value: 0.7353481018352888.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ ÏµúÏ†ÅÏùò ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï∂úÎ†•\n",
        "best_params = study.best_params\n",
        "print(f\"üîπ Best Params: {best_params}\")"
      ],
      "metadata": {
        "id": "wstrLe8ufGSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5423c98f-826e-4a8e-d54c-b2be223ff7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Best Params: {'lgbm_n_estimators': 436, 'lgbm_learning_rate': 0.014768177339829039, 'lgbm_num_leaves': 87, 'lgbm_max_depth': 12, 'lgbm_subsample': 0.6628572716745862, 'lgbm_colsample_bytree': 0.7129596637133632, 'xgb_n_estimators': 347, 'xgb_learning_rate': 0.006945354657061471, 'xgb_max_depth': 10, 'xgb_subsample': 0.5033839027206597, 'xgb_colsample_bytree': 0.5110990994971739, 'catboost_iterations': 300, 'catboost_learning_rate': 0.011409195641314061, 'catboost_depth': 12, 'catboost_l2_leaf_reg': 9.955027922167531, 'meta_model': 'logistic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ ÏµúÏ†ÅÏùò Stacking Î™®Îç∏ ÏÉùÏÑ±\n",
        "final_lgbm = LGBMClassifier(\n",
        "    n_estimators=best_params['lgbm_n_estimators'],\n",
        "    learning_rate=best_params['lgbm_learning_rate'],\n",
        "    num_leaves=best_params['lgbm_num_leaves'],\n",
        "    max_depth=best_params['lgbm_max_depth'],\n",
        "    subsample=best_params['lgbm_subsample'],\n",
        "    colsample_bytree=best_params['lgbm_colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "final_xgb = XGBClassifier(\n",
        "    n_estimators=best_params['xgb_n_estimators'],\n",
        "    learning_rate=best_params['xgb_learning_rate'],\n",
        "    max_depth=best_params['xgb_max_depth'],\n",
        "    subsample=best_params['xgb_subsample'],\n",
        "    colsample_bytree=best_params['xgb_colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "final_catboost = CatBoostClassifier(\n",
        "    iterations=best_params['catboost_iterations'],\n",
        "    learning_rate=best_params['catboost_learning_rate'],\n",
        "    depth=best_params['catboost_depth'],\n",
        "    l2_leaf_reg=best_params['catboost_l2_leaf_reg'],\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "OTG28yuOE9KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ ÏµúÏ†Å Meta Model ÏÑ§Ï†ï\n",
        "if best_params['meta_model'] == 'logistic':\n",
        "    final_meta_model = LogisticRegression()\n",
        "else:\n",
        "    final_meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# üîπ ÏµúÏ†Å Stacking Î™®Îç∏ ÌïôÏäµ\n",
        "final_stacked_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lgbm', final_lgbm),\n",
        "        ('xgb', final_xgb),\n",
        "        ('catboost', final_catboost)\n",
        "    ],\n",
        "    final_estimator=final_meta_model,\n",
        "    stack_method='predict_proba',\n",
        "    passthrough=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "final_stacked_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lAj39CSYFBTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff54265-6bf8-44c9-ff74-8603d2922eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(estimators=[('lgbm',\n",
              "                                LGBMClassifier(colsample_bytree=0.7129596637133632,\n",
              "                                               learning_rate=0.014768177339829039,\n",
              "                                               max_depth=12, n_estimators=436,\n",
              "                                               num_leaves=87, random_state=42,\n",
              "                                               subsample=0.6628572716745862)),\n",
              "                               ('xgb',\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=0.51109...\n",
              "                                              max_delta_step=None, max_depth=10,\n",
              "                                              max_leaves=None,\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              multi_strategy=None,\n",
              "                                              n_estimators=347, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              random_state=42, ...)),\n",
              "                               ('catboost',\n",
              "                                <catboost.core.CatBoostClassifier object at 0x7f2fd91da010>)],\n",
              "                   final_estimator=LogisticRegression(), n_jobs=-1,\n",
              "                   passthrough=True, stack_method='predict_proba')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                                LGBMClassifier(colsample_bytree=0.7129596637133632,\n",
              "                                               learning_rate=0.014768177339829039,\n",
              "                                               max_depth=12, n_estimators=436,\n",
              "                                               num_leaves=87, random_state=42,\n",
              "                                               subsample=0.6628572716745862)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=0.51109...\n",
              "                                              max_delta_step=None, max_depth=10,\n",
              "                                              max_leaves=None,\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              multi_strategy=None,\n",
              "                                              n_estimators=347, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              random_state=42, ...)),\n",
              "                               (&#x27;catboost&#x27;,\n",
              "                                &lt;catboost.core.CatBoostClassifier object at 0x7f2fd91da010&gt;)],\n",
              "                   final_estimator=LogisticRegression(), n_jobs=-1,\n",
              "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                                LGBMClassifier(colsample_bytree=0.7129596637133632,\n",
              "                                               learning_rate=0.014768177339829039,\n",
              "                                               max_depth=12, n_estimators=436,\n",
              "                                               num_leaves=87, random_state=42,\n",
              "                                               subsample=0.6628572716745862)),\n",
              "                               (&#x27;xgb&#x27;,\n",
              "                                XGBClassifier(base_score=None, booster=None,\n",
              "                                              callbacks=None,\n",
              "                                              colsample_bylevel=None,\n",
              "                                              colsample_bynode=None,\n",
              "                                              colsample_bytree=0.51109...\n",
              "                                              max_delta_step=None, max_depth=10,\n",
              "                                              max_leaves=None,\n",
              "                                              min_child_weight=None,\n",
              "                                              missing=nan,\n",
              "                                              monotone_constraints=None,\n",
              "                                              multi_strategy=None,\n",
              "                                              n_estimators=347, n_jobs=None,\n",
              "                                              num_parallel_tree=None,\n",
              "                                              random_state=42, ...)),\n",
              "                               (&#x27;catboost&#x27;,\n",
              "                                &lt;catboost.core.CatBoostClassifier object at 0x7f2fd91da010&gt;)],\n",
              "                   final_estimator=LogisticRegression(), n_jobs=-1,\n",
              "                   passthrough=True, stack_method=&#x27;predict_proba&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.7129596637133632,\n",
              "               learning_rate=0.014768177339829039, max_depth=12,\n",
              "               n_estimators=436, num_leaves=87, random_state=42,\n",
              "               subsample=0.6628572716745862)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.5110990994971739, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.006945354657061471,\n",
              "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=347, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7f2fd91da010&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
        "y_val_pred = final_stacked_model.predict_proba(X_val)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "print(f'‚úÖ Validation ROC-AUC (Stacking + Optuna): {roc_auc:.4f}')"
      ],
      "metadata": {
        "id": "mjJr8MO7hHIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9230db-489f-4a83-95f7-639a69361013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Validation ROC-AUC (Stacking + Optuna): 0.7353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏòàÏ∏°\n",
        "test_preds = final_stacked_model.predict_proba(df_test)[:, 1]"
      ],
      "metadata": {
        "id": "5Ot7QQ2VqrlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
        "submission = pd.DataFrame({'ID': df_test_ids, 'probability': test_preds})\n",
        "submission.to_csv('submission_7.csv', index=False)\n",
        "print(\"‚úÖ Submission file saved: submission_7.csv\")"
      ],
      "metadata": {
        "id": "B6FKad_-fIE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265c0311-d89b-4944-d760-0038c304d910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Submission file saved: submission_7.csv\n"
          ]
        }
      ]
    }
  ]
}