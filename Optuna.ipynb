{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ql_v2DJz5o"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna"
      ],
      "metadata": {
        "id": "LTkk53PpKF1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ë¡œë“œ\n",
        "df_train = pd.read_csv('./train.csv')\n",
        "df_test = pd.read_csv('./test.csv')\n",
        "df_sample_submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "_HEzwjrdKHkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B7WWAfaxiwvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ID ì œê±°\n",
        "df_train.drop(columns=['ID'], inplace=True)\n",
        "df_test_ids = df_test['ID']\n",
        "df_test.drop(columns=['ID'], inplace=True)"
      ],
      "metadata": {
        "id": "23gIxZ7BKJid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬\n",
        "X = df_train.drop(columns=['ì„ì‹  ì„±ê³µ ì—¬ë¶€'])\n",
        "y = df_train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']"
      ],
      "metadata": {
        "id": "E4m5cdlyKK9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# ìˆ«ìí˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
        "simple_imputer = SimpleImputer(strategy=\"mean\")  # ë˜ëŠ” \"median\" (ì¤‘ì•™ê°’ ì‚¬ìš© ê°€ëŠ¥)\n",
        "\n",
        "X[numeric_features] = simple_imputer.fit_transform(X[numeric_features])\n",
        "df_test[numeric_features] = simple_imputer.transform(df_test[numeric_features])"
      ],
      "metadata": {
        "id": "5-Oje5JoKMiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X[categorical_features] = encoder.fit_transform(X[categorical_features])\n",
        "df_test[categorical_features] = encoder.transform(df_test[categorical_features])"
      ],
      "metadata": {
        "id": "iJsM8QjfKPQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Scaling (StandardScaler ì ìš©)\n",
        "scaler = StandardScaler()\n",
        "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
        "df_test[numeric_features] = scaler.transform(df_test[numeric_features])"
      ],
      "metadata": {
        "id": "ir25FhFSKRRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature Selection (LightGBM ê¸°ë°˜)\n",
        "lgbm = LGBMClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "lgbm.fit(X, y)\n",
        "feature_importance = pd.Series(lgbm.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "selected_features = feature_importance[feature_importance > 0.001].index.tolist()\n",
        "X = X[selected_features]\n",
        "df_test = df_test[selected_features]"
      ],
      "metadata": {
        "id": "45d-rjTaKS6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í›ˆë ¨ / ê²€ì¦ ë°ì´í„° ë¶„ë¦¬\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "P1tU3Rq4KUY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Optunaë¥¼ ì´ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 800),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.02),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 80),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "    model = LGBMClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    return roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "best_params = study.best_params\n",
        "print(f\"ğŸ”¹ Best Params: {best_params}\")"
      ],
      "metadata": {
        "id": "F1cEfxSSKWQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ\n",
        "lgbm_best = LGBMClassifier(**best_params)\n",
        "lgbm_best.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# ğŸ”¹ ê²€ì¦ ë°ì´í„° í‰ê°€ (Validation ROC-AUC)\n",
        "y_val_pred = lgbm_best.predict_proba(X_val)[:, 1]\n",
        "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
        "print(f'âœ… Validation ROC-AUC: {roc_auc:.4f}')"
      ],
      "metadata": {
        "id": "avz4uxyCKYe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
        "test_preds = lgbm_best.predict_proba(df_test)[:, 1]"
      ],
      "metadata": {
        "id": "kqg2k0RMKbds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "submission = pd.DataFrame({'ID': df_test_ids, 'probability': test_preds})\n",
        "submission.to_csv('submission_5.csv', index=False)\n",
        "print(\"âœ… Submission file saved: submission_5.csv\")"
      ],
      "metadata": {
        "id": "gvvgvdIhKc7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}